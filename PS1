
import util
import numpy as np
import matplotlib.pyplot as plt

np.seterr(all='raise')


factor = 2.0

class LinearModel(object):
  """Base class for linear models.
  Attributes:
    theta: np.ndarray, dtype=np.float64, shape=(n_features,). Weights vector for
      the model.
  """

  def __init__(self, theta=None):
    """
    Args:
      theta: (See class definition)
    """
    self.theta = theta

  def fit(self, x, y):
    """Fits the linear model to x -> y using np.linalg.solve.
    Remember to update self.theta with the fitted model parameters.
    Args:
      x: np.ndarray, dtype=np.float64, shape=(n_examples, n_features). Inputs.
      y: np.ndarray, dtype=np.float64, shape=(n_examples,). Outputs.
    Returns: Nothing
    """
    pass
    # *** START CODE HERE ***
    
    X_t = np.transpose(x)
    X_t_X = np.dot(X_t, x)
    X_t_y = np.dot(X_t, y)
    self.theta = np.linalg.solve(X_t_X, X_t_y).reshape(-1,1)
    
    # *** END CODE HERE ***

  def predict(self, x):
    """ Makes a prediction given a new set of input features.
    Args:
      x: np.ndarray, dtype=np.float64, shape=(n_examples, n_features). Model input.
    Returns: np.float64. Model output.
    """
    pass
    # *** START CODE HERE ***
    
    predict_x = x.dot(self.theta)
    return(predict_x)

    # *** END CODE HERE ***

  @staticmethod
  def create_poly(k, x):
    """ Generates polynomial features of the input data x.
    Args:
      x: np.ndarray, dtype=np.float64, shape=(n_examples,). Training inputs.
    
    Returns: np.ndarray, dtype=np.float64, shape=(n_examples, k+1). Polynomial
      features of x with powers 0 to k (inclusive).
    """
    pass
    # *** START CODE HERE ***
    create polynomial  for give k & x.in form of x-poly = 
    [x0 = 1, x1 = x^1 x2 = x^2 x3 = x^3]........
    so if x is in shape [n=70, 1] after this function you will get a new x_poly of shape [n, k+1]
    run_exp is basically for getting initial theta by training x & y using fit, create_poly...once after training , 
    you got theta, you will use plot_y again to get polynomial form of that data and 
    use theta you received from 2 steps and that will give you plot_y that will plot your graph
    
    poly = PolynomialFeatures(degree = k)
    k=3
    X_poly = poly.fit_transform(X)
    poly.fit(X_poly, y)
    lin2 = LinearRegression()
    lin2.fit(X_poly, y)
    poly_out shape ([n, k+1]) #adding the first term?
    print(np.poly1d(p))
    
    k=3
    X_poly = np.arange(start=1, stop =k+1, step=1),reshape ([n,k+1])
    np.power(X_poly,n)
    np.expand_dims(x, axis=1)
    np.hstack((1,X_poly))
    return (X_poly)

    
    So something like this:
[ 1           1         ....       1
 n1x       n2x      ....        n_nx
....
n_1x^3  n_2x^3 ...... n_nx^3]
where n is the number of examples provided as input. 
    
    
    # *** END CODE HERE ***

  @staticmethod
  def create_sin(k, x):
    """ Generates sine and polynomial features of the input data x.
    Args:
      x: np.ndarray, dtype=np.float64, shape=(n_examples,). Training inputs.
    
    Returns: np.ndarray, dtype=np.float64, shape=(n_examples, k+2). Sine (column
      0) and polynomial (columns 1 to k+1) features of x with powers 0 to k
      (inclusive).
    """
    pass
    # *** START CODE HERE ***
    
        #Adding additional feature in polynomial features, generating a x_sine[n, k+2] shape matrix
        
    x_sine = np.arrange(x),reshape ([k+2,n])
    np.power(poly,n)
    np.expand_dims(x, axis=1)
    np.hstack((X_poly,x_sine))
    np.sin(np.array(a))
    
    
    and as for create_sin features, you do something similar 
only this time your feature vector deals with an additional sin(x) function for each example provided.
    
    # *** END CODE HERE ***

def run_exp(train_path, sine=False, ks=[1, 2, 3, 5, 10, 20], filename='plot.png'):
  train_x,train_y=util.load_dataset(train_path,add_intercept=False)
  plot_x = np.ones([1000, 1])
  plot_x[:, 0] = np.linspace(-factor*np.pi, factor*np.pi, 1000)
  plt.figure()
  plt.scatter(train_x, train_y)

  for k in ks:
      '''
      Our objective is to train models and perform predictions on plot_x data
      '''
      # *** START CODE HERE ***
      # *** END CODE HERE ***
      '''
      Here plot_y are the predictions of the linear model on the plot_x data
      '''
      plt.ylim(-2, 2)
      plt.plot(plot_x[:, 0], plot_y, label='k=%d' % k)

  plt.legend()
  plt.savefig(filename)
  plt.clf()


def main(train_path, small_path, eval_path):
  '''
  Run all experiments
  '''
  run_exp(train_path, False, [3], 'large-poly3.png')
  run_exp(train_path, True, [1, 2, 3, 5, 10, 20], 'large-sine.png')
  run_exp(train_path, False, [1, 2, 3, 5, 10, 20], 'large-poly.png')
  run_exp(small_path, True, [1, 2, 3, 5, 10, 20], 'small-sine.png')
  run_exp(small_path, False, [1, 2, 3, 5, 10, 20], 'small-poly.png')

if __name__ == '__main__':
  main(train_path='train.csv',
      small_path='small.csv',
      eval_path='test.csv')
